{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "style_transfer_reproducibility_attempt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEUGlrJSB15C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "6349d25e-5316-4879-ae9e-30ae75909ead"
      },
      "source": [
        "!pip install --upgrade torchtest"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtest\n",
            "  Downloading https://files.pythonhosted.org/packages/42/b1/eb572ef3dce32bfcc3bf60be6360cef0d01a58bde0c76f2e205234d1ff08/torchtest-0.5-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: torch in /usr/local/lib/python3.6/dist-packages (from torchtest) (1.4.0)\n",
            "Installing collected packages: torchtest\n",
            "Successfully installed torchtest-0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3HzPR2AnpN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"IMPORTS\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torchtest import assert_vars_change, assert_vars_same, test_suite\n",
        "from scipy.ndimage import gaussian_filter1d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJhdMaArAfhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"TESTING CODE BLOCK\"\"\"\n",
        "\n",
        "torch.manual_seed(1)\n",
        "\n",
        "def get_gradient_norm(model):\n",
        "  norms = 0\n",
        "  for param in model.parameters():\n",
        "    norms += param.grad.data.detach().norm(2)\n",
        "  return norms\n",
        "\n",
        "def visualize_history_norm(history, history_name, zoom_axis=[], sigma=5):\n",
        "  plt.plot(gaussian_filter1d(history, sigma))\n",
        "  plt.xlabel('Iteration')\n",
        "  plt.ylabel(history_name)\n",
        "  if zoom_axis:\n",
        "    plt.axis(zoom_axis)\n",
        "  plt.show()\n",
        "\n",
        "# this function should take a batch from the dataloader and:\n",
        "#\n",
        "# pass the batch through the model all at once and collect\n",
        "# that output in a variable\n",
        "#\n",
        "# pass each item in the batch through the model by itself \n",
        "# and collect the output such that it's the same shape as the\n",
        "# original batch\n",
        "#\n",
        "# compare these two using torch.allclose to make sure they are\n",
        "# the same!\n",
        "def test_forward_pass(model, dataloader):\n",
        "  data, _ = next(iter(dataloader))\n",
        "  output_batch = model(data.float())\n",
        "  output_single = []\n",
        "  for datum in data:\n",
        "    output_single.append(model(datum.float()))\n",
        "\n",
        "  assert torch.allclose(output_batch, torch.cat(output_single)), 'Forward pass is batch dependent'\n",
        "\n",
        "# this function should take a batch from the dataloader and:\n",
        "#\n",
        "# pass the batch through the model all at once then do a \n",
        "# backwards and collect the gradient\n",
        "#\n",
        "# pass each item in the batch through the model by itself \n",
        "# do backwards on each item (accummulating the gradient),\n",
        "# and collect the gradient at the end\n",
        "#\n",
        "# compare these two using torch.allclose to make sure they are\n",
        "# the same!\n",
        "def test_backward_pass(model, dataloader, loss):\n",
        "  model.zero_grad()\n",
        "  data, targets = next(iter(dataloader))\n",
        "  _loss_batch = loss(model(data.float()), targets.long())\n",
        "  _loss_batch.backward()\n",
        "  accumulated_batch = get_gradient_norm(model)\n",
        "  \n",
        "  model.zero_grad() \n",
        "  for datum, target in zip(data, targets):\n",
        "    _loss_single = loss(model(datum.float()), target.long().reshape(1))\n",
        "    _loss_single.backward()\n",
        "  accumulated_single = get_gradient_norm(model)/data.shape[0]\n",
        "  \n",
        "  assert torch.allclose(accumulated_batch.reshape(1), accumulated_single.reshape(1), atol=1e-3), 'loss function is cross-linking data'\n",
        "  \n",
        "def test_gradient_flow(model, dataloader, loss, magnitude=-5, compare_prev_layers=True, compare_prev_layers_magnitude=3):\n",
        "  # pass data through the model, then compare the gradient at each\n",
        "  # layer in the model. the gradient should never become really\n",
        "  # tiny, as this means the earlier layers of the model will be\n",
        "  # tough to train. your network is probably too deep!\n",
        "  \n",
        "  model.zero_grad()\n",
        "  data, targets = next(iter(dataloader))\n",
        "  _loss_batch = loss(model(data.float()), targets.long())\n",
        "  _loss_batch.backward()\n",
        "  grad_norms = []\n",
        "  for param in model.parameters():\n",
        "    grad_norms.append(param.grad.data.norm(2).detach())\n",
        "  last_norm = grad_norms[-1]\n",
        "  for norm in reversed(grad_norms[:(len(grad_norms) - 1)]):\n",
        "    if comparelayers:\n",
        "      assert not torch.log10(last_norm) - torch.log10(norm) > compare_prev_layers_magnitude, 'Early gradients vanish too quickly compared to later layers'\n",
        "    assert torch.log10(last_norm) > magnitude, 'Tensor magnitude is too small'\n",
        "    last_norm = norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jzC-D7hHa8kt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "ebf65805-7c5a-40c4-f673-5c67b068ecd7"
      },
      "source": [
        "\"\"\"\n",
        "READ THIS!!\n",
        "\n",
        "Since the deep photo style transfer (DPST) builds on the neural transfer algorithm\n",
        "and we are focusing on DPST, I figure it would be unnecessary to try to \n",
        "reproduce the neural style from the original paper. Instead, I am following this tutorial:\n",
        "\n",
        "https://pytorch.org/tutorials/advanced/neural_style_tutorial.html\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from PIL import Image # python image library\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import copy\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "device = 'cpu'\n",
        "imsize = 128\n",
        "loader = transforms.Compose([transforms.Resize(imsize), transforms.ToTensor()])\n",
        "\n",
        "def image_loader(image_name):\n",
        "  image = Image.open(image_name)\n",
        "  image = loader(image)\n",
        "  print('Images shape initial', image.shape)\n",
        "  image = image.unsqueeze(0) # gets right dimension at particular size\n",
        "  print('Image shape after unsqueeze', image.shape)\n",
        "  return image.to(device, torch.float)\n",
        "\n",
        "%cd /content/drive/My Drive/temp_images\n",
        "style_img = image_loader('picasso.jpg')\n",
        "content_img = image_loader('dancing.jpg')\n",
        "\n",
        "assert style_img.size() == content_img.size(), 'Incorrect Sizing'\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/temp_images\n",
            "Images shape initial torch.Size([3, 128, 128])\n",
            "Image shape after unsqueeze torch.Size([1, 3, 128, 128])\n",
            "Images shape initial torch.Size([3, 128, 128])\n",
            "Image shape after unsqueeze torch.Size([1, 3, 128, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}